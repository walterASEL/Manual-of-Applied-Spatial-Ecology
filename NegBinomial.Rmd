---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Negative Binomial

1\. Open the script NegBinomial.Rmd" and run code directly from the script

2\. First we need to load the packages needed for the exercise

```{r warning=FALSE, message=FALSE}
library(plyr)
library(adehabitatHR)
library(zoo)
library(MASS)#For nb models
library(sf)
library(terra)
library(sfheaders)
library(exactextractr)
library(dplyr)
```

3\. Now let's have a separate section of code to include projection information we will use throughout the exercise. In previous versions, these lines of code were within each block of code

```{r warning=FALSE, message=FALSE}
ll.crs <- st_crs(4269) 
utm.crs <- st_crs(9001) 
albers.crs <- st_crs(5070)
```

4\. Load files for the mule deer dataset and clean up the dataset as we have done in previous exercises

```{r}
muleys<-read.csv("data/DCmuleysedited.csv", header=T, sep=",")

muleys$NewDate<-as.POSIXct(muleys$GPSFixTime, format="%Y.%m.%d %H:%M:%S", origin="1970-01-01")
muleys <- subset(muleys, muleys$id != "D19")

##Sort Data
muleys <- muleys[order(muleys$id, muleys$NewDate),]

fix_rate <- function(x){
  print(paste("Individual:", x$id[1]))
  dates=range(x$NewDate)
  print(paste("Range:", dates))
  days=as.numeric(round(diff(range(x$NewDate)), digits=0))
  print(paste("Number of monitoring days:", days))
  sched=as.numeric(round(median(abs(diff(sapply(x$NewDate[2:nrow(x)], difftime, time1 = x$NewDate[1], units = "mins", simplify = T))))))
  print(paste("Scheduled fix rate (min):", sched))
  expected=as.numeric(days)*round(1440/(as.numeric(sched)), digits=0)#1440 minutes in a day
  print(paste("Expected number of positions:", expected))
  success <- nrow(x)
  print(paste("Number of recorded positions", success))
  percentfix <- round(success/expected*100)
  print(paste("Fix rate success = ", percentfix,"%", sep=" "))
}

fix_deer <- ddply(muleys, .(as.factor(id)), fix_rate)

##TIME DIFF NECESSARY IN BBMM CODE
timediff <- diff(muleys$NewDate)*60
## remove first entry without any difference 
muleys <- muleys[-1,] 
muleys$timelag <-as.numeric(abs(timediff))
##Remove locations greater than 5.5 hours apart in time
muleys <- subset(muleys, muleys$timelag < 19800)
summary(muleys$timelag)

muleys <- subset(muleys, muleys$X > 680000)# & muleys$GPS.UTM.Easting != "NA")
muleys$id <- factor(muleys$id)

##Make a spatial data frame of locations after removing outliers
muleysSPDF <- st_as_sf(muleys, coords = c("Long", "Lat"), crs = ll.crs)
plot(st_geometry(muleysSPDF), axes=T)#To visualize all locations
utm.spdf <- st_transform(muleysSPDF, data = muleys, crs = utm.crs)
plot(st_geometry(utm.spdf), axes=T)#To visualize all locations

##change muleysSPDF from UTM to Albers
muleys.sf <-st_transform(muleysSPDF, crs=albers.crs)

#Subset locations by year for season-specific RSFs if needed
#winter2012 <- muleys
# winter2012 <- crop(muleys.spdf,muleysbuffSP)
# winter2012$id <- droplevels(winter2012$id)
```

5\. If we get some NA errors because our grid does not encompass our panther locations then we can expand the grid size extending beyond our locations using methods in an earlier exercise.

```{r}
# Create vectors of the x and y points using boundary box created around deer locations
bb <- st_bbox(muleys.sf)
     
increment = 2512#628 m daily move distance times 4 
minx=(min(bb$xmin)-(increment))
maxx=(max(bb$xmax)+(increment))
miny=(min(bb$ymin)-(increment))
maxy=(max(bb$ymax)+(increment))

my_bbox = st_bbox(c(xmin = minx, xmax = maxx, 
                    ymin = miny, ymax = maxy),
                  crs = 5070)

AlbersSP <- st_as_sfc(my_bbox)
```

6\. Now we need to set up our sample circles across our study area keeping in mind our discussions on "available" habitats. For this exercise, we will keep it simple by only including a polygon around our mule deer locations. This is for demonstration only, the appropriate study area should be specific to your study design and objectives. We also need to determine what is the appropriate size of our sample circles. In this case, we will use the mean daily movement distance for mule deer we determined to be 628 meters. This will be the radius of our sample circles.

```{r}
buff.increment = 1256#twice the buffer size
g = expand.grid(
    x = seq(my_bbox$xmin, my_bbox$xmax, by = buff.increment),
    y = seq(my_bbox$ymin, my_bbox$ymax, by = buff.increment))

g.grid <- st_as_sf(g, coords = c("x", "y"), crs = albers.crs)

#g_sfc <- sfc_point(as.matrix(g)) %>% 
#  st_set_crs(5070)
plot(st_geometry(g.grid)) 
muleysbuffSP2=st_buffer(g.grid,628) %>% st_as_sfc()
plot(st_geometry(muleysbuffSP2),add=T)
plot(st_geometry(muleys.sf),add=T,col="red")
```

7\. We will start here by creating covariate layers specifically for the year of interest, in this case crop data from NRCS for 2011

```{r warning=FALSE, message=FALSE}
# Then clip buffer from crop11 layer
crop11 <- rast("data/crop11clip.tif")
mulcrop11clip<-crop(crop11, muleysbuffSP2)
#Crop categories
#1 = Sunflower,summer crops, random crops, grassland
#2 = Winter crops
#3 = Alfalfa
#4 = Forest
#5 = Shrubland

#Or use FedData package now
#library(FedData)
#crop11nass <- NASS <- get_nass_cdl(template = AlbersSP, label = "NRCS CO", year = 2011)

#Reclassify into 5 habitat categories
m11 <- c(-Inf,0,NA, 5.5, 6.5, 1, 22.5, 24.5, 2, 26.5, 27.5, 2, 29.5, 30.5, 2, 35.5, 36.5, 
  3, 3.5, 4.5, 1, .5, 1.5, 1, 11.5, 12.5, 1, 27.5, 28.5, 1, 31.5, 33.5, 1,  42.5, 43.5, 1, 
  47.5, 49.5, 1, 58.5, 59.5, 1, 60.5, 61.5, 1, 65.5, 69.5, 1, 76.5, 77.5, 1, 110.5, 
  111.5, 1, 120.5, 124.5, 1, 130.5, 131.5, 1, 175.5, 190.5, 1, 194.5, 195.5, 1, 228.5,
  229.5, 1, 140.5, 143.5, 4, 170.5, 171.5, 1, 180.5, 181.5, 1, 36.5, 37.5, 1, 151.5, 
  152.5, 5, 41.5, 42.5, 1, 204.5, 205.5, 1, 230,Inf,NA)
rclmat11 <- matrix(m11, ncol=3, byrow=TRUE)
crop11rc <- classify(mulcrop11clip, rclmat11)
plot(crop11rc)

##Create cover layer
cov <- c(-Inf,3.75,0, 3.76, 5,1)#cover=forest only
rclmatcov <- matrix(cov, ncol=3, byrow=TRUE)
cover <- classify(crop11rc, rclmatcov)
plot(cover)

d_cover <- distance(cover,target="0")
plot(d_cover)
##Bring in roads layer
roads<-st_read("data/AlbersRoads.shp")

#Clip using AlbersSP
cliproads <- st_intersection(roads, AlbersSP)

plot(st_geometry(cliproads))
plot(st_geometry(muleys.spdf),add=T,col="red")
plot(muleysbuffSP2, add=TRUE)
```

8\. The downside of creating distance to roads with spatstat in Exercise 8.2 is that it is not in a raster so we need to create a raster of distance to roads for every raster cell in layer1 before grabbing values or making our predictive surface.

We will start by using the Rasterize function to create a raster of the road shapefile with crop data used as a mask. A mask will give the spatial resolution and projection information to the raster you plan to create.

```{r}
roadvect <- vect(cliproads)
d_roadrast <- terra::distance(rasterize(roadvect,crop11rc))
plot(d_roadrast)

compareGeom(crop11rc,d_cover,d_roadrast)

#Now we need to extract all raster layers, grid and create a stack of all rasters
r <- c(crop11rc, d_cover, d_roadrast)
names(r) <- c("crop11","d_cover","d_roads")
plot(r)
names(r)

##MAKE ALL RASTER LAYERS DATAFRAMES TO COMBINE LATER
crop11df <- as.data.frame(crop11rc, xy=TRUE)
#Distance to cover
d_covdf <- as.data.frame(d_cover, xy=TRUE)
#Distance to roads
final_roaddf <- as.data.frame(d_roadrast, xy=TRUE)

#Combine data frames for Crop and Distance to Cover and Roads
layers1 = cbind(crop11df, d_covdf,final_roaddf)
layers1 = layers1[,c(3,6,9,7:8)]
names(layers1) = c("crop","d_cover","d_roads","x", "y")
#write.table(layers1,"layer1.txt",sep=",",col.names=TRUE, quote=FALSE)

ext <- exact_extract(r, muleysbuffSP2, function(values, coverage_fraction) weighted.mean(values,coverage_fraction,na.rm=TRUE), stack_apply=TRUE)

#NOTE above that for each buffered circle in the study area, the "exact_extract" function resulted in means for distance to cover and roads for all sample circles but "crop" resulted in mean cover categories so need to run separate with more appropriate code (see below).
```

9\. Code below extracts by land cover category and determines how many cells of each type were in each sample circle.

```{r eval=FALSE}
# sum_cover <- function(x){
#   list(x %>%
#     group_by(value) %>%
#     summarize(total_area = sum(coverage_area)) %>%
#     mutate(proportion = total_area/sum(total_area)))
# 
# }
ex_crop <- exact_extract(crop11rc, st_as_sf(muleysbuffSP2))
head(ex_crop[[1]])#Here we can see the percent of each category in buffer IDs 1-6 for category 52

et=lapply(ex_crop,table)

prop <- list()
for(i in 1:length(ex_crop)[1] ){
  prop[[i]] <- round((margin.table(et[[i]],1)/margin.table(et[[i]])),digits = 6)
}
prop

M <- coredata(do.call(cbind, lapply(prop, zoo)))
colnames(M) <- NULL
#Transpose matrix so land cover become separate columns of data
matrix <- t(M)
#Now convert the matrix to a data frame so it is easier to manipulate
dfland <- as.data.frame(matrix)

#Assing column names to land cover
colnames(dfland) <- c("sunflower","wintercrop","alfalfa","forest","shrub")
head(dfland)
#Cell size of raster layers
res(crop11rc)
```

10\. Now that we have Land Cover in a similar format as the distance-to-derived data, we want to convert ext(the combined extracted rasters) into a data frame so it is easier to manipulate as well. The "extract" function in the raster package is supposed to be able to do this but does not work for some reason.

```{r eval=FALSE}
habitat_units_buffwin12 <- cbind(ext, dfland)
colnames(habitat_units_buffwin12) <- c("crop","d_cover","d_roads","sunflower","wintercrop","alfalfa","forest","shrub")
```

11\. Now we need to convert to a data frame for nb modeling. Read in animal_locations.txt or convert to data frame from above

```{r eval=FALSE}
#locations = read.table("deer_locations.txt", sep='\t', header=T)
#locations.spdf <- crop(muleys.spdf,muleysbuffSP)
locations.xy <- as.data.frame(st_coordinates(muleys.sf))
locations.df = st_drop_geometry(muleys.sf)
locations <- cbind(locations.df, locations.xy)
#Clean up so fewer columns
locations <- locations[c(-1,-3:-22)]

#Add xy columns of circle centroids
mbuff.xy <- as.data.frame(st_coordinates(g.grid))
habitat_units_buffwin12$x <- mbuff.xy$X
habitat_units_buffwin12$y <- mbuff.xy$Y

plot(habitat_units_buffwin12$x, habitat_units_buffwin12$y, type='p', cex=1.5)
points(locations$X, locations$Y, col="red", cex=0.5, pch=19)
```

12\. Calculate number of animal locations in each sampled habitat unit(see code in "count_locations.R").

```{r warning=FALSE, message=FALSE, eval=FALSE}
# Source code file containing functions used below.
source("data/count_locations.R")

pooled.locations = locations
colnames(pooled.locations) <- c("ID","x","y")
pooled.locations$ID = 1
NB = F.count.relocations(locations.df = pooled.locations, 
    habitat.units.df = habitat_units_buffwin12, 
    habitat.unit.size = 628)
# List of column names:
names(NB)

#Look at the range in number of locations in our sample circles
summary(NB$n.locations)

#Now run a population-level model for a few covariates (forest, road). NOTE: If you run models for each animal, will have to average coefficients across animals and top model(s)
nb = glm.nb(n.locations ~ offset(log(total)) + forest + d_roads, data=NB)
summary(nb)

#-----------------------------------------------------------------------------------
# Proportion of 0 counts in data
sum(NB$n.locations == 0)/nrow(NB)

nb.density = structure(
function # Probability mass function for NB2

# Description: This function gives the probability that a discrete random variable, X, 
#is exactly equal to some value  according to a NB2 distribution.
# Returns: Pr(X=k)

(k, 
### value at which to estimate probability
### Pr(X=k)
mu, 
### NB2 estimate of mu
theta
### NB2 estimate of theta
){

	(gamma(theta+k)/(gamma(theta)*factorial(k)))*
		(mu^k)*(theta^theta)/
		((mu+theta)^(theta+k))
		
})
# Expected proportion under NB2 model
nb.density(k=0, mu=mean(NB$n.locations), theta=0.1861) 
             # (Note: use estimated theta of the model output found in summary statement above)
# The value above can be interpreted as: 
# "A NB2 distribution with theta=0.1861 and mu=0.9196 should have an average of 32% zero values"

#Observed
zero = NB$n.locations == 0
sum(zero)   #total number of zeros
mean(zero)  #proportion that are zeros

#Expected based on NB distribution and our observed over-dispersions
theta = mean(NB$n.locations)^2 / (var(NB$n.locations) - mean(NB$n.locations)) 
check = rnegbin(n=10000, mu=mean(NB$n.locations), theta=theta)
check.zeros = check == 0
mean(check.zeros)

#saveRDS(habitat_units_buffwin12, "Exercise.8.6.rds")
```
